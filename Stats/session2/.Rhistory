group_by(ID) %>%
summarise(date_session1=mean(utc_date))
View(dates)
PC.both.complete$utc_date <- dmy(PC.both.complete$utc_date)
View(PC.both.complete)
# Combine data frames.
PC.both.complete <- rbind(PC.session1,PC.session2)
PC.both.complete$ID <- as.factor(PC.both.complete$ID)
# Only include ID's who completed both sessions.
DNF <- PC.both.complete %>%
group_by(ID) %>%
summarise(Count = n_distinct(session))
DNF <- subset(DNF,Count==1)
PC.both.complete <- PC.both.complete[ ! PC.both.complete$ID %in% DNF$ID, ]
n_distinct(PC.both.complete$ID) # N = 98 who completed both sessions
# Rename "block" to bias for transparency.
names(PC.both.complete)[10] <- "bias"
PC.both.complete$bias <- ifelse(PC.both.complete$bias=="PC-S","S-Bias",ifelse(PC.both.complete$bias=="PC-SH","SH-Bias",""))
# Check number of IDs by headphone checks; X fail both checks.
Counts <- PC.both.complete %>%
group_by(spreadsheet_name, Headphone.1, Headphone.2) %>%
summarise(Count = n_distinct(ID))
# Remove subjects who failed both headphone checks.
PC.both.complete <- filter(PC.both.complete, Headphone.1 == "Pass" | Headphone.2 == "Pass")
PC.both.complete$ID <- factor(PC.both.complete$ID)
# See how many participants remain after removing double headphone check fails.
n_distinct(PC.both.complete$ID) # N=83
# Drop NA trials.
PC.both.complete <- subset(PC.both.complete,zone_type=="response_keyboard_single")
# Change response from string to binary integer.
PC.both.complete$resp1 <- ifelse(PC.both.complete$response=="sign",1,0)
# Add vector for continuum step.
PC.both.complete$step <- ifelse(PC.both.complete$stimulus=="TW001_20SS_80SH-001.mp3",1,
ifelse(PC.both.complete$stimulus=="TW002_30SS_70SH-001.mp3",2,
ifelse(PC.both.complete$stimulus=="TW003_40SS_60SH-001.mp3",3,
ifelse(PC.both.complete$stimulus=="TW004_50SS_50SH-001.mp3",4,
ifelse(PC.both.complete$stimulus=="TW005_60SS_40SH-001.mp3",5,
ifelse(PC.both.complete$stimulus=="TW006_70SS_30SH-001.mp3",6,
ifelse(PC.both.complete$stimulus=="TW007_80SS_20SH-001.mp3",7,NA)))))))
# Filter out participants who did not meet S&M18 endpoint accuracy criteria (<80% accuracy) on either session.
exclude <- subset(PC.both.complete, step==1 | step==7)
exclude <- exclude %>%
group_by(ID,step,session) %>%
summarize(endpointResp=mean(resp1))
exclude <- subset(exclude,step==1&endpointResp>.2|step==7&endpointResp<.8)
# Count how many participants are going to be excluded for accuracy.
n_distinct(exclude$ID) # N = 20
# Remove those participants.
PC.both.complete <- PC.both.complete[ ! PC.both.complete$ID %in% exclude$ID, ]
# Check how many subjects reman after excluding based on both headphone check fails and acccuracy.
n_distinct(PC.both.complete$ID) # N = 63
# Check distribution of presentation order.
PC.both.complete %>%
group_by(order) %>%
summarise(Count = n_distinct(ID)) # S_SH n=32, SH_S n=31
# Calculate statistics about length between session 1 and 2.
library(lubridate)
dmy(PC.both.complete$utc_date)
PC.both.complete$utc_date <- as.date(dmy_hms(PC.both.complete$utc_date))
PC.both.complete$utc_date <- as.Date(dmy_hms(PC.both.complete$utc_date))
dates <- PC.both.complete %>%
select(ID,session,utc_date)
View(dates)
mean(dates$utc_date)
dates <- PC.both.complete %>%
select(ID,session,utc_date) %>%
group_by(ID,session1) %>%
summarise(date=mean(utc_date))
dates <- PC.both.complete %>%
select(ID,session,utc_date) %>%
group_by(ID,session) %>%
summarise(date=mean(utc_date))
View(dates)
dates <- PC.both.complete %>%
select(ID,session,utc_date) %>%
group_by(ID,session) %>%
summarise(date=mean(utc_date)) %>%
spread(session,date)
View(dates)
View(dates)
dates <- PC.both.complete %>%
select(ID,session,utc_date) %>%
group_by(ID,session) %>%
summarise(date=mean(utc_date)) %>%
spread(session,date) %>%
summarise(diff=dates$`Session 2`-dates$`Session 1`)
View(dates)
dates <- PC.both.complete %>%
select(ID,session,utc_date) %>%
group_by(ID,session) %>%
summarise(date=mean(utc_date)) %>%
spread(session,date) %>%
group_by(ID) %>%
summarise(diff=dates$`Session 2`-dates$`Session 1`)
dates <- PC.both.complete %>%
select(ID,session,utc_date) %>%
group_by(ID,session) %>%
summarise(date=mean(utc_date)) %>%
spread(session,date) %>%
group_by(ID) %>%
summarise(diff=dates$`Session 2`-dates$`Session 1`)
View(dates)
diff=dates$`Session 2`-dates$`Session 1`
rm(diff)
source('C:/Users/David/Desktop/SM-PBR-18-Replication/Stats/S&M_replication.R', echo=TRUE)
dates <- PC.both.complete %>%
select(ID,session,utc_date) %>%
group_by(ID,session) %>%
summarise(date=mean(utc_date)) %>%
spread(session,date) %>%
group_by(ID) %>%
summarise(diff=dates$`Session 2`-dates$`Session 1`)
setwd("C:/Users/David/Desktop/SM-PBR-18-Replication/Stats")
rm(list = ls(all = TRUE))
# Load packages.
# Data manipulation.
library(data.table)
library(dplyr)
library(stringr)
library(rio)
library(tidyverse)
library(janitor)
# Plots.
library(ggplot2)
library(cowplot)
# Analyses.
library(afex)
library(lme4)
library(lmerTest)
library(emmeans)
library(quickpsy)
theme_set(theme_bw())
#### Import Data ####
# Session 1
# Set working directory.
setwd("./session1")
# Read in files.
file_names <- list.files(path = ".", pattern = "*.csv", all.files = FALSE,
full.names = FALSE, recursive = FALSE)
# Create data frame.
session1 <- data.frame()
# Loop to create combined dataframe.
for (i in file_names) {
data <- fread(i, header = TRUE, sep = ",")
session1 <- rbind(session1, data)
}
# Various housekeeping things.
# make variable names syntactically valid.
session1 <- clean_names(session1)
# Select only columns we want.
session1 <- dplyr::filter(session1,session1$trial_number != "BEGIN TASK")
session1 <- dplyr::filter(session1,session1$trial_number != "END TASK")
session1 <- select(session1,participant_public_id,spreadsheet_name,spreadsheet_row,trial_number,
zone_type,reaction_time,response,attempt,correct,display,fname,branch_ee59,branch_52fz,utc_date)
# Remove trials where stimulus failed to load.
session1 <- subset(session1,spreadsheet_name!="")
# Rename some variables (naming in Gorilla is opaque)
names(session1)[12] <- "Headphone.1"
names(session1)[13] <- "Headphone.2"
names(session1)[11] <- "stimulus"
names(session1)[10] <- "block"
names(session1)[1] <- "ID"
# Set vectors.
session1$spreadsheet_row <- as.numeric(session1$spreadsheet_row)
session1$trial_number <- as.numeric(session1$trial_number)
session1$reaction_time <- as.numeric(session1$reaction_time)
session1$correct <- as.numeric(session1$correct)
session1$order <- substr(session1$spreadsheet_name,1,4)
session1$session <- "Session 1"
# Separate data by block.
PC.session1 <- subset(session1,grepl("PC",block))
LD.session1 <- subset(session1,grepl("LD",block))
# Number of participants.
n_distinct(session1$ID) # N=108 (15 subjects data rejected before analysis for non-compliance)
# Session 2
# Set working directory.
setwd("../session2")
# Read in files.
file_names <- list.files(path = ".", pattern = "*.csv", all.files = FALSE,
full.names = FALSE, recursive = FALSE)
# Create data frame.
session2 <- data.frame()
# Loop to create combined dataframe.
for (i in file_names) {
data <- fread(i, header = TRUE, sep = ",")
session2 <- rbind(session2, data)
}
# Various housekeeping things.
# Make variable names syntactically valid.
session2 <- clean_names(session2)
# Select only columns we want.
session2 <- dplyr::filter(session2,session2$trial_number != "BEGIN TASK")
session2 <- dplyr::filter(session2,session2$trial_number != "END TASK")
session2 <- select(session2,participant_public_id,spreadsheet_name,spreadsheet_row,trial_number,
zone_type,reaction_time,response,attempt,correct,display,fname,branch_ee59,branch_52fz,utc_date)
# Remove trials where stimulus failed to load.
session2 <- subset(session2,spreadsheet_name!="")
# Rename some variables (naming in Gorilla is opaque)
names(session2)[12] <- "Headphone.1"
names(session2)[13] <- "Headphone.2"
names(session2)[11] <- "stimulus"
names(session2)[10] <- "block"
names(session2)[1] <- "ID"
# Set vectors.
session2$spreadsheet_row <- as.numeric(session2$spreadsheet_row)
session2$trial_number <- as.numeric(session2$trial_number)
session2$reaction_time <- as.numeric(session2$reaction_time)
session2$correct <- as.numeric(session2$correct)
session2$order <- substr(session2$spreadsheet_name,1,4)
session2$session <- "Session 2"
# Separate data by block.
PC.session2 <- subset(session2,grepl("PC",block))
LD.session2 <- subset(session2,grepl("LD",block))
# Number of participants.
n_distinct(session2$ID) # N=99
# Clean up.
rm(data)
# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
# Combine data frames.
PC.both.complete <- rbind(PC.session1,PC.session2)
PC.both.complete$ID <- as.factor(PC.both.complete$ID)
# Only include ID's who completed both sessions.
DNF <- PC.both.complete %>%
group_by(ID) %>%
summarise(Count = n_distinct(session))
DNF <- subset(DNF,Count==1)
PC.both.complete <- PC.both.complete[ ! PC.both.complete$ID %in% DNF$ID, ]
n_distinct(PC.both.complete$ID) # N = 98 who completed both sessions
# Rename "block" to bias for transparency.
names(PC.both.complete)[10] <- "bias"
PC.both.complete$bias <- ifelse(PC.both.complete$bias=="PC-S","S-Bias",ifelse(PC.both.complete$bias=="PC-SH","SH-Bias",""))
# Check number of IDs by headphone checks; X fail both checks.
Counts <- PC.both.complete %>%
group_by(spreadsheet_name, Headphone.1, Headphone.2) %>%
summarise(Count = n_distinct(ID))
# Remove subjects who failed both headphone checks.
PC.both.complete <- filter(PC.both.complete, Headphone.1 == "Pass" | Headphone.2 == "Pass")
PC.both.complete$ID <- factor(PC.both.complete$ID)
# See how many participants remain after removing double headphone check fails.
n_distinct(PC.both.complete$ID) # N=83
# Drop NA trials.
PC.both.complete <- subset(PC.both.complete,zone_type=="response_keyboard_single")
# Change response from string to binary integer.
PC.both.complete$resp1 <- ifelse(PC.both.complete$response=="sign",1,0)
# Add vector for continuum step.
PC.both.complete$step <- ifelse(PC.both.complete$stimulus=="TW001_20SS_80SH-001.mp3",1,
ifelse(PC.both.complete$stimulus=="TW002_30SS_70SH-001.mp3",2,
ifelse(PC.both.complete$stimulus=="TW003_40SS_60SH-001.mp3",3,
ifelse(PC.both.complete$stimulus=="TW004_50SS_50SH-001.mp3",4,
ifelse(PC.both.complete$stimulus=="TW005_60SS_40SH-001.mp3",5,
ifelse(PC.both.complete$stimulus=="TW006_70SS_30SH-001.mp3",6,
ifelse(PC.both.complete$stimulus=="TW007_80SS_20SH-001.mp3",7,NA)))))))
# Filter out participants who did not meet S&M18 endpoint accuracy criteria (<80% accuracy) on either session.
exclude <- subset(PC.both.complete, step==1 | step==7)
exclude <- exclude %>%
group_by(ID,step,session) %>%
summarize(endpointResp=mean(resp1))
exclude <- subset(exclude,step==1&endpointResp>.2|step==7&endpointResp<.8)
# Count how many participants are going to be excluded for accuracy.
n_distinct(exclude$ID) # N = 20
# Remove those participants.
PC.both.complete <- PC.both.complete[ ! PC.both.complete$ID %in% exclude$ID, ]
# Check how many subjects reman after excluding based on both headphone check fails and acccuracy.
n_distinct(PC.both.complete$ID) # N = 63
# Check distribution of presentation order.
PC.both.complete %>%
group_by(order) %>%
summarise(Count = n_distinct(ID)) # S_SH n=32, SH_S n=31
# Calculate statistics about length between session 1 and 2.
library(lubridate)
# Convert to date.
PC.both.complete$utc_date <- as.Date(dmy_hms(PC.both.complete$utc_date))
# Summarise.
dates <- PC.both.complete %>%
select(ID,session,utc_date) %>%
group_by(ID,session) %>%
summarise(date=mean(utc_date)) %>%
spread(session,date) %>%
group_by(ID) %>%
summarise(diff=dates$`Session 2`-dates$`Session 1`)
setwd("C:/Users/David/Desktop/SM-PBR-18-Replication/Stats")
rm(list = ls(all = TRUE))
# Load packages.
# Data manipulation.
library(data.table)
library(dplyr)
library(stringr)
library(rio)
library(tidyverse)
library(janitor)
# Plots.
library(ggplot2)
library(cowplot)
# Analyses.
library(afex)
library(lme4)
library(lmerTest)
library(emmeans)
library(quickpsy)
theme_set(theme_bw())
#### Import Data ####
# Session 1
# Set working directory.
setwd("./session1")
# Read in files.
file_names <- list.files(path = ".", pattern = "*.csv", all.files = FALSE,
full.names = FALSE, recursive = FALSE)
# Create data frame.
session1 <- data.frame()
# Loop to create combined dataframe.
for (i in file_names) {
data <- fread(i, header = TRUE, sep = ",")
session1 <- rbind(session1, data)
}
# Various housekeeping things.
# make variable names syntactically valid.
session1 <- clean_names(session1)
# Select only columns we want.
session1 <- dplyr::filter(session1,session1$trial_number != "BEGIN TASK")
session1 <- dplyr::filter(session1,session1$trial_number != "END TASK")
session1 <- select(session1,participant_public_id,spreadsheet_name,spreadsheet_row,trial_number,
zone_type,reaction_time,response,attempt,correct,display,fname,branch_ee59,branch_52fz,utc_date)
# Remove trials where stimulus failed to load.
session1 <- subset(session1,spreadsheet_name!="")
# Rename some variables (naming in Gorilla is opaque)
names(session1)[12] <- "Headphone.1"
names(session1)[13] <- "Headphone.2"
names(session1)[11] <- "stimulus"
names(session1)[10] <- "block"
names(session1)[1] <- "ID"
# Set vectors.
session1$spreadsheet_row <- as.numeric(session1$spreadsheet_row)
session1$trial_number <- as.numeric(session1$trial_number)
session1$reaction_time <- as.numeric(session1$reaction_time)
session1$correct <- as.numeric(session1$correct)
session1$order <- substr(session1$spreadsheet_name,1,4)
session1$session <- "Session 1"
# Separate data by block.
PC.session1 <- subset(session1,grepl("PC",block))
LD.session1 <- subset(session1,grepl("LD",block))
# Number of participants.
n_distinct(session1$ID) # N=108 (15 subjects data rejected before analysis for non-compliance)
# Session 2
# Set working directory.
setwd("../session2")
# Read in files.
file_names <- list.files(path = ".", pattern = "*.csv", all.files = FALSE,
full.names = FALSE, recursive = FALSE)
# Create data frame.
session2 <- data.frame()
# Loop to create combined dataframe.
for (i in file_names) {
data <- fread(i, header = TRUE, sep = ",")
session2 <- rbind(session2, data)
}
# Various housekeeping things.
# Make variable names syntactically valid.
session2 <- clean_names(session2)
# Select only columns we want.
session2 <- dplyr::filter(session2,session2$trial_number != "BEGIN TASK")
session2 <- dplyr::filter(session2,session2$trial_number != "END TASK")
session2 <- select(session2,participant_public_id,spreadsheet_name,spreadsheet_row,trial_number,
zone_type,reaction_time,response,attempt,correct,display,fname,branch_ee59,branch_52fz,utc_date)
# Remove trials where stimulus failed to load.
session2 <- subset(session2,spreadsheet_name!="")
# Rename some variables (naming in Gorilla is opaque)
names(session2)[12] <- "Headphone.1"
names(session2)[13] <- "Headphone.2"
names(session2)[11] <- "stimulus"
names(session2)[10] <- "block"
names(session2)[1] <- "ID"
# Set vectors.
session2$spreadsheet_row <- as.numeric(session2$spreadsheet_row)
session2$trial_number <- as.numeric(session2$trial_number)
session2$reaction_time <- as.numeric(session2$reaction_time)
session2$correct <- as.numeric(session2$correct)
session2$order <- substr(session2$spreadsheet_name,1,4)
session2$session <- "Session 2"
# Separate data by block.
PC.session2 <- subset(session2,grepl("PC",block))
LD.session2 <- subset(session2,grepl("LD",block))
# Number of participants.
n_distinct(session2$ID) # N=99
# Clean up.
rm(data)
# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
# Combine data frames.
PC.both.complete <- rbind(PC.session1,PC.session2)
PC.both.complete$ID <- as.factor(PC.both.complete$ID)
# Only include ID's who completed both sessions.
DNF <- PC.both.complete %>%
group_by(ID) %>%
summarise(Count = n_distinct(session))
DNF <- subset(DNF,Count==1)
PC.both.complete <- PC.both.complete[ ! PC.both.complete$ID %in% DNF$ID, ]
n_distinct(PC.both.complete$ID) # N = 98 who completed both sessions
# Rename "block" to bias for transparency.
names(PC.both.complete)[10] <- "bias"
PC.both.complete$bias <- ifelse(PC.both.complete$bias=="PC-S","S-Bias",ifelse(PC.both.complete$bias=="PC-SH","SH-Bias",""))
# Check number of IDs by headphone checks; X fail both checks.
Counts <- PC.both.complete %>%
group_by(spreadsheet_name, Headphone.1, Headphone.2) %>%
summarise(Count = n_distinct(ID))
# Remove subjects who failed both headphone checks.
PC.both.complete <- filter(PC.both.complete, Headphone.1 == "Pass" | Headphone.2 == "Pass")
PC.both.complete$ID <- factor(PC.both.complete$ID)
# See how many participants remain after removing double headphone check fails.
n_distinct(PC.both.complete$ID) # N=83
# Drop NA trials.
PC.both.complete <- subset(PC.both.complete,zone_type=="response_keyboard_single")
# Change response from string to binary integer.
PC.both.complete$resp1 <- ifelse(PC.both.complete$response=="sign",1,0)
# Add vector for continuum step.
PC.both.complete$step <- ifelse(PC.both.complete$stimulus=="TW001_20SS_80SH-001.mp3",1,
ifelse(PC.both.complete$stimulus=="TW002_30SS_70SH-001.mp3",2,
ifelse(PC.both.complete$stimulus=="TW003_40SS_60SH-001.mp3",3,
ifelse(PC.both.complete$stimulus=="TW004_50SS_50SH-001.mp3",4,
ifelse(PC.both.complete$stimulus=="TW005_60SS_40SH-001.mp3",5,
ifelse(PC.both.complete$stimulus=="TW006_70SS_30SH-001.mp3",6,
ifelse(PC.both.complete$stimulus=="TW007_80SS_20SH-001.mp3",7,NA)))))))
# Filter out participants who did not meet S&M18 endpoint accuracy criteria (<80% accuracy) on either session.
exclude <- subset(PC.both.complete, step==1 | step==7)
exclude <- exclude %>%
group_by(ID,step,session) %>%
summarize(endpointResp=mean(resp1))
exclude <- subset(exclude,step==1&endpointResp>.2|step==7&endpointResp<.8)
# Count how many participants are going to be excluded for accuracy.
n_distinct(exclude$ID) # N = 20
# Remove those participants.
PC.both.complete <- PC.both.complete[ ! PC.both.complete$ID %in% exclude$ID, ]
# Check how many subjects reman after excluding based on both headphone check fails and acccuracy.
n_distinct(PC.both.complete$ID) # N = 63
# Check distribution of presentation order.
PC.both.complete %>%
group_by(order) %>%
summarise(Count = n_distinct(ID)) # S_SH n=32, SH_S n=31
# Calculate statistics about length between session 1 and 2.
library(lubridate)
# Convert to date.
PC.both.complete$utc_date <- as.Date(dmy_hms(PC.both.complete$utc_date))
# Summarise.
dates <- PC.both.complete %>%
select(ID,session,utc_date) %>%
group_by(ID,session) %>%
summarise(date=mean(utc_date)) %>%
spread(session,date) %>%
group_by(ID) %>%
summarise(diff=dates$`Session 2`-dates$`Session 1`)
# Summarise.
dates <- PC.both.complete %>%
select(ID,session,utc_date) %>%
group_by(ID,session) %>%
summarise(date=mean(utc_date)) %>%
spread(session,date) %>%
group_by(ID) %>%
summarise(diff=dates$`Session 2`-dates$`Session 1`)
# Summarise.
dates <- PC.both.complete %>%
select(ID,session,utc_date) %>%
group_by(ID,session) %>%
summarise(date=mean(utc_date)) %>%
spread(session,date)
dates$diff <- dates$`Session 2`-dates$`Session 1`
View(dates)
Rmisc::summarySE(dates,measurevar = "diff")
View(dates)
View(dates)
range(dates$diff)
View(dates)
PC.both.complete$step <- ifelse(PC.both.complete$stimulus=="TW001_20SS_80SH-001.mp3",1,
ifelse(PC.both.complete$stimulus=="TW002_30SS_70SH-001.mp3",2,
ifelse(PC.both.complete$stimulus=="TW003_40SS_60SH-001.mp3",3,
ifelse(PC.both.complete$stimulus=="TW004_50SS_50SH-001.mp3",4,
ifelse(PC.both.complete$stimulus=="TW005_60SS_40SH-001.mp3",5,
ifelse(PC.both.complete$stimulus=="TW006_70SS_30SH-001.mp3",6,
ifelse(PC.both.complete$stimulus=="TW007_80SS_20SH-001.mp3",7,NA)))))))
# Calculate stats for plot.
PC.both.complete.stats <- Rmisc::summarySE(data = PC.both.complete, measurevar="resp1",groupvars = c("step","bias","order","session"))
# Plot.
ggplot(PC.both.complete.stats, aes(x=step, y=resp1, colour=factor(bias),linetype=factor(order))) +
geom_point(stat='summary', fun.y='mean', size=2.5) +
geom_line(stat='summary', fun.y='mean', size=0.75) +
geom_errorbar(aes(ymin=resp1-se,ymax=resp1+se),width=.5) +
facet_wrap(~session) +
scale_x_continuous('Continuum step', breaks=c(1:7)) +
scale_y_continuous('Percent "sign" responses', breaks=c(0,0.25,0.5,0.75,1), labels=c(0,25,50,75,100)) +
scale_color_manual('Biasing Condition', labels=c('S-Bias','SH-Bias'),values=c("#B03A2E","#2874A6")) +
scale_linetype_manual('Order', labels=c('S-SH','SH-S'),values=c("solid","dotted")) +
coord_cartesian(ylim=c(0,1)) +
theme(text = element_text(size=14))
ggsave("replication_PC.png",device="png",dpi="retina",type="cairo")
# Prep models.
PC.both.complete$bias <- as.factor(PC.both.complete$bias)
PC.both.complete$order <- as.factor(PC.both.complete$order)
PC.both.complete$session <- as.factor(PC.both.complete$session)
PC.both.complete$step <- scale(PC.both.complete$step)
# Build models.
model1 <- mixed(resp1 ~ step*bias*order*session +
(bias:step:session||ID) + (bias||ID) + (step||ID) + (session||ID), family=binomial(link="logit"),data=PC.both.complete,method="LRT",expand_re = TRUE,
control = glmerControl(optimizer="bobyqa",calc.derivs = FALSE, optCtrl = list(maxfun = 1500000)))
# Explore interactions
# First, simple effects to see which orders/sessions bias effect is significant at.
biasXorderXsession <- emmeans(model1, ~bias*order*session,interaction="pairwise")
pairs(biasXorderXsession,simple="bias")
# Is there anything to trend that bias by order interaction is weaker in session 2?
foo <- emmeans(model1,~bias|session*order)
con1 <- contrast(foo, interaction = "pairwise")
pairs(con1, by = NULL)
pairs(biasXorderXsession)
source('C:/Users/David/Desktop/SM-PBR-18-Replication/Stats/S&M_replication.R', echo=TRUE)
# Summarize model1.
model1
